strategy: ddp
benchmark: True
pretrained: False
sync_batchnorm: False
clip_grad: null
precision: 16
epochs: &epochs 100
# --------------------------------------
# Dataset parameters
# --------------------------------------
train_dataset:
  name: SklFlowDataset
  params:
    data_path: &data_path data/hmpear_flow/hmpear.pkl
    split: [train, val]
val_dataset:
  name: SklFlowDataset
  params:
    data_path: *data_path
    split: test
test_dataset:
  name: SklFlowDataset
  params:
    data_path: data/hmpear_flow/mmfi.pkl
    split: test
# --------------------------------------
# Optimizer parameters
# --------------------------------------
optim_name: AdamW
optim_params:
  lr: 0.0001
  weight_decay: 0.00001
# --------------------------------------
# Learning rate scheduler parameters
# --------------------------------------
sched_name: LinearWarmupCosineAnnealingLR
sched_params:
  warmup_epochs: 20
  max_epochs: *epochs
  warmup_start_lr: 0.00001
  eta_min: 0.00001
# --------------------------------------
# Model parameters
# --------------------------------------
mode: train
model_name: CTR_GCN
model_params:
  num_point: 15
  graph_name: 'itop'
  in_channels: 3
  drop_out: 0.1
  adaptive: true
# --------------------------------------
# Loss parameters
# --------------------------------------
loss_name: MSELoss
loss_params: null
# weight for auxiliary losses
w_loc: 1.0
w_flow: 1.0
# --------------------------------------
# Augmentation parameters
# --------------------------------------
train_pipeline:
  - name: UniformSample
    params:
      pad_type: 'end'
      clip_len: 30
  # - name: ToITOP
  #   params: null
  - name: ToTensor
    params: null
val_pipeline: &val_pipeline
  - name: UniformSample
    params:
      pad_type: 'end'
      clip_len: 30
  # - name: ToITOP
  #   params: null
  - name: ToTensor
    params: null
test_pipeline: *val_pipeline